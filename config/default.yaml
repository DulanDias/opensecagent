# OpenSecAgent - Default Configuration
# Override via OPENSECAGENT_CONFIG or --config

agent:
  name: opensecagent
  version: "0.1.0"
  data_dir: /var/lib/opensecagent
  log_dir: /var/log/opensecagent
  run_dir: /run/opensecagent

# Threat registry (past threats for LLM context)
threat_registry:
  dir: ""  # default: {data_dir}/threats

# Command execution (optional run-as user for LLM-suggested commands)
execution:
  run_as: ""  # e.g. opensecagent; leave empty to run as daemon user

# PDF reports output directory
reports:
  dir: ""  # default: {data_dir}/reports

# Environment: dev | staging | prod
environment: prod

# Policy: action tier allowed (0=alert only, 1=soft containment, 2=strong, 3=emergency)
action_tier_max: 1

# Maintenance windows (no Tier-1+ actions during these; UTC)
maintenance_windows: []

# Scan frequency: set scan_level to quick | standard | deep, or leave empty to use intervals below
# Presets: quick (lighter), standard (default), deep (more frequent)
scan_frequencies:
  quick:
    host_interval_sec: 600
    docker_interval_sec: 120
    drift_interval_sec: 600
    detector_interval_sec: 120
    llm_scan_interval_sec: 7200
  standard:
    host_interval_sec: 300
    docker_interval_sec: 60
    drift_interval_sec: 300
    detector_interval_sec: 60
    llm_scan_interval_sec: 3600
  deep:
    host_interval_sec: 180
    docker_interval_sec: 45
    drift_interval_sec: 180
    detector_interval_sec: 45
    llm_scan_interval_sec: 1800

scan_level: ""   # quick | standard | deep (empty = use collector/detector/llm_agent values below)

# Collectors (used when scan_level is empty; otherwise overridden by scan_frequencies[scan_level])
collector:
  host_interval_sec: 300
  docker_interval_sec: 60
  drift_interval_sec: 300
  critical_files:
    - /etc/passwd
    - /etc/group
    - /etc/sudoers
    - /etc/ssh/sshd_config
    - /etc/hosts
    - /etc/crontab
    - /etc/cron.d
    # dirs as glob
    - /etc/cron.d/*

# Detectors (detector_interval_sec used when scan_level is set)
detector:
  detector_interval_sec: 60
  auth_failure_threshold: 5
  auth_failure_window_sec: 300
  baseline_learning_days: 3
  resource_detector_enabled: true
  resource_cpu_percent: 90
  resource_memory_percent: 90
  # Network: alert when throughput exceeds threshold (MB/s)
  network_detector_enabled: true
  network_mb_per_sec_threshold: 100
  # Nginx: nginx -t and optional security checks (server_tokens off)
  nginx_audit_enabled: true
  nginx_config_paths: ["/etc/nginx/nginx.conf"]
  nginx_check_security: true
  # Firewall: require UFW active (or iptables)
  firewall_audit_enabled: true
  firewall_require_active: true
  # npm audit: scan paths for package.json, run npm audit
  npm_audit_enabled: true
  npm_audit_paths: ["/var/www", "/opt", "/home"]
  npm_audit_max_depth: 4

# Notifications: provider = smtp | resend
notifications:
  provider: smtp
  admin_emails: []
  smtp:
    host: ""
    port: 587
    use_tls: true
    user: ""
    password: ""
    from: "OpenSecAgent <noreply@localhost>"
  resend:
    api_key: ""
    from: ""   # e.g. "OpenSecAgent <alerts@yourdomain.com>"
  immediate_severities: [P1, P2]
  digest:
    enabled: true
    hour_utc: 8
    minute: 0

# LLM: provider = openai | anthropic; model_scan for routine scan, model_resolve for active remediation
llm:
  enabled: false
  provider: openai
  api_key: ""
  model: gpt-4o-mini
  model_scan: ""   # e.g. gpt-4o-mini (cheaper); blank = use model
  model_resolve: "" # e.g. gpt-4o or claude-3-5-sonnet-20241022 (advanced); blank = use model
  base_url: ""     # for OpenAI-compatible endpoints (ignored for anthropic)
  max_tokens: 2048
  agent_max_iterations: 10
  redact_patterns: ["password", "secret", "token", "key", "credential"]

# Control plane (optional)
control_plane:
  enabled: false
  url: ""
  agent_key: ""

# Audit
audit:
  file: /var/log/opensecagent/audit.jsonl
  max_size_mb: 100
  retain_days: 90

# Full activity log (every collector, detector, command, LLM call)
activity:
  enabled: true
  file: /var/log/opensecagent/activity.jsonl
  log_dir: /var/log/opensecagent

# LLM Agent (command loop: suggest → execute → feedback)
llm_agent:
  enabled: false
  run_on_incident: true   # run agent loop when P1/P2 incident detected
  run_interval_sec: 3600  # or run periodically (0 = disabled)
  agent_max_iterations: 10
